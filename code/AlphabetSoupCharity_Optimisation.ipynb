{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow3Z5u2iWcD-",
        "outputId": "f6bf373d-ae3a-4c4a-878e-2814c54c676b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras_tuner)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (13.6.0)\n",
            "Collecting namex (from keras-core->keras_tuner)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_tuner) (0.1.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-core, keras_tuner\n",
            "Successfully installed keras-core-0.1.7 keras_tuner-1.4.5 kt-legacy-1.0.5 namex-0.0.7\n",
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "# importing dependencies\n",
        "!pip install keras_tuner\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16JW4UIZcNfE"
      },
      "source": [
        "# Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lGEy4FmArU0q"
      },
      "outputs": [],
      "source": [
        "# importing data and converting to pandas df.\n",
        "# I have created another df here \"application_df_2\" because I would like to see how the model does without the alterations made to\n",
        "# the 'APPLICATION_TYPE' and 'CLASSIFICATION' columns\n",
        "\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df_2 = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J1YXNTl0WyDg"
      },
      "outputs": [],
      "source": [
        "# Dropping EIN and NAME columns\n",
        "application_df = application_df.drop(columns=['EIN','NAME'])\n",
        "application_df_2 = application_df_2.drop(columns=['EIN','NAME'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iUBNLeaCchhr"
      },
      "outputs": [],
      "source": [
        "# Finding application types with frequency less than 500\n",
        "type_counts=application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_types_to_replace=[type_counts.index[i] for i in range(len(type_counts)) if type_counts[i]<500]\n",
        "\n",
        "# combining into one category\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bZUNKXxxcyVU"
      },
      "outputs": [],
      "source": [
        "# Finding classifications with frequency less than 1000 thousand\n",
        "class_counts=application_df['CLASSIFICATION'].value_counts()\n",
        "classifications_to_replace=class_counts.loc[lambda x : x<1000].index\n",
        "\n",
        "# combining these into one category\n",
        "\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "x8sISZyQfVUZ",
        "outputId": "6e70f4c1-7dc5-4a3b-86cc-65910d237855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                       0   \n",
              "1       1   108590              1                       0   \n",
              "2       1     5000              0                       0   \n",
              "3       1     6692              1                       0   \n",
              "4       1   142590              1                       0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                     1                     0                    0   \n",
              "1                     0                     0                    1   \n",
              "2                     0                     0                    0   \n",
              "3                     0                     0                    1   \n",
              "4                     0                     0                    1   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                    0                    0                    0  ...   \n",
              "1                    0                    0                    0  ...   \n",
              "2                    0                    1                    0  ...   \n",
              "3                    0                    0                    0  ...   \n",
              "4                    0                    0                    0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                  0                       0                         0   \n",
              "1                  1                       0                         0   \n",
              "2                  0                       0                         0   \n",
              "3                  0                       1                         0   \n",
              "4                  0                       0                         1   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                   0                 0                       0   \n",
              "1                   0                 0                       0   \n",
              "2                   0                 0                       0   \n",
              "3                   0                 0                       0   \n",
              "4                   0                 0                       0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0                0                  0                         1   \n",
              "1                0                  0                         1   \n",
              "2                0                  0                         1   \n",
              "3                0                  0                         1   \n",
              "4                0                  0                         1   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                         0  \n",
              "1                         0  \n",
              "2                         0  \n",
              "3                         0  \n",
              "4                         0  \n",
              "\n",
              "[5 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c96c4fb-c9da-4d0a-8af3-b5363d8b505a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c96c4fb-c9da-4d0a-8af3-b5363d8b505a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c96c4fb-c9da-4d0a-8af3-b5363d8b505a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c96c4fb-c9da-4d0a-8af3-b5363d8b505a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37853697-8cc4-4011-a0b7-e6b6f5cb4fb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37853697-8cc4-4011-a0b7-e6b6f5cb4fb9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37853697-8cc4-4011-a0b7-e6b6f5cb4fb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Converting categorical data to numeric\n",
        "\n",
        "dummies = pd.get_dummies(application_df[[\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"]])\n",
        "\n",
        "# Concatenate the dummies to original dataframe\n",
        "applications_cleaned_df = pd.concat([application_df, dummies], axis=1)\n",
        "applications_cleaned_df_2 = pd.concat([application_df_2, dummies], axis=1)\n",
        "\n",
        "# drop the values\n",
        "applications_cleaned_df=applications_cleaned_df.drop([\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"], axis=1)\n",
        "applications_cleaned_df_2=applications_cleaned_df_2.drop([\"APPLICATION_TYPE\",\"AFFILIATION\",\"CLASSIFICATION\",\"USE_CASE\",\"ORGANIZATION\",\"INCOME_AMT\",\"SPECIAL_CONSIDERATIONS\"], axis=1)\n",
        "\n",
        "applications_cleaned_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ukp2MnrBfZSj"
      },
      "outputs": [],
      "source": [
        "# Splitting data into testing and training data and standardising\n",
        "\n",
        "X = applications_cleaned_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "y = applications_cleaned_df[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code does the same as the previous cell but for applications_cleaned_df_2\n",
        "\n",
        "# Splitting data into testing and training data and standardising\n",
        "\n",
        "X_2 = applications_cleaned_df_2.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "y_2 = applications_cleaned_df_2[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, random_state=42, stratify=y_2)\n",
        "\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler_2 = StandardScaler().fit(X_train_2)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled_2 = X_scaler_2.transform(X_train_2)\n",
        "X_test_scaled_2 = X_scaler_2.transform(X_test_2)"
      ],
      "metadata": {
        "id": "l7X6Yhv_YyvT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First attempt at optimisation"
      ],
      "metadata": {
        "id": "OtCSx3fT7Z83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-8Fq1kWfgM3",
        "outputId": "2c947a3d-b5ee-499f-e78d-adb9ba4050cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 43)                1892      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 21)                924       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 21)                462       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 21)                462       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3762 (14.70 KB)\n",
            "Trainable params: 3762 (14.70 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "# In this attempt I will add another layer of neurons in case the model is underfitting\n",
        "\n",
        "# input dimension\n",
        "num_features = X.shape[1]\n",
        "\n",
        "# First layer of neurons\n",
        "\n",
        "num_neurons_1 = num_features\n",
        "\n",
        "# Second layer (first hidden layer)\n",
        "num_neurons_2 = math.floor(num_features/2)\n",
        "\n",
        "# Third layer (second hidden layer)\n",
        "num_neurons_3 = num_neurons_2\n",
        "\n",
        "# Fourth layer (third hidden layer)\n",
        "num_neurons_4 = num_neurons_2\n",
        "\n",
        "# initalising model\n",
        "\n",
        "nn_1 = tf.keras.models.Sequential()\n",
        "\n",
        "# input layer\n",
        "\n",
        "nn_1.add(tf.keras.layers.Dense(units=num_neurons_1, activation=\"sigmoid\", input_dim=num_features))\n",
        "\n",
        "# First hidden layer\n",
        "nn_1.add(tf.keras.layers.Dense(units=num_neurons_2, activation=\"sigmoid\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn_1.add(tf.keras.layers.Dense(units=num_neurons_3, activation=\"sigmoid\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn_1.add(tf.keras.layers.Dense(units=num_neurons_4, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer (single neuron)\n",
        "nn_1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCMv8L6yiZU9",
        "outputId": "0bd05093-73b7-4617-cbcd-048be5bb8aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 4s 3ms/step - loss: 0.6123 - accuracy: 0.6795\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5738 - accuracy: 0.7311\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7310\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7320\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5619 - accuracy: 0.7316\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5586 - accuracy: 0.7322\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5563 - accuracy: 0.7322\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5554 - accuracy: 0.7326\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5543 - accuracy: 0.7332\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5530 - accuracy: 0.7326\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5523 - accuracy: 0.7338\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.7339\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7341\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7328\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7349\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7333\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5491 - accuracy: 0.7337\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7336\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7336\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7344\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7329\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7353\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7345\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7346\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7346\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7353\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7348\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7349\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7347\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7355\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7353\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7361\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7360\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7367\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7355\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7365\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7361\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7371\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7354\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5434 - accuracy: 0.7367\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7358\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7364\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7380\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7376\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7362\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7372\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7381\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7370\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7375\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "import keras as keras\n",
        "\n",
        "nn_1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "fit_model = nn_1.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33B-CXEKj12V",
        "outputId": "fbec3311-11ff-4942-de4a-1a9be7c46fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 1s 1ms/step - loss: 0.5542 - accuracy: 0.7249\n",
            "Loss: 0.5541577935218811, Accuracy: 0.7248979806900024\n"
          ]
        }
      ],
      "source": [
        "model_loss, model_accuracy = nn_1.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_1.save(\"second_model.h5\")"
      ],
      "metadata": {
        "id": "z7tffsN_iUug"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second attempt at optimisation"
      ],
      "metadata": {
        "id": "UUjy4UXVBj_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# In this attempt I will more neurons to each layer in case the model is underfitting\n",
        "\n",
        "# input dimension\n",
        "num_features = X.shape[1]\n",
        "\n",
        "# We require at least as many neurons in the input layer as there are features, so initally we can let\n",
        "\n",
        "num_neurons_1 = num_features\n",
        "\n",
        "# For an initial guess we can let the number of neurons in the first hidden layer to be\n",
        "\n",
        "num_neurons_2 = num_features\n",
        "\n",
        "# And the number of neurons in the second hidden layer to be\n",
        "\n",
        "num_neurons_3 = num_features\n",
        "\n",
        "# initalising model\n",
        "\n",
        "nn_2 = tf.keras.models.Sequential()\n",
        "\n",
        "# initially we can just use the sigmoid for all activation functions, though\n",
        "# the output layer will need a sigmoid activation function since we are doing binary classification\n",
        "\n",
        "# input layer\n",
        "\n",
        "nn_2.add(tf.keras.layers.Dense(units=num_neurons_1, activation=\"sigmoid\", input_dim=num_features))\n",
        "\n",
        "# First hidden layer\n",
        "nn_2.add(tf.keras.layers.Dense(units=num_neurons_2, activation=\"sigmoid\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn_2.add(tf.keras.layers.Dense(units=num_neurons_3, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer (single neuron)\n",
        "nn_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mTSIQl_Bl5o",
        "outputId": "978b6b56-7ba6-43f7-ea97-296532feb316"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 43)                1892      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 43)                1892      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 43)                1892      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5720 (22.34 KB)\n",
            "Trainable params: 5720 (22.34 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "fit_model = nn_2.fit(X_train_scaled, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Pvpk7yCQXp",
        "outputId": "28817a92-ce65-4da4-cfd9-bcd2381c073b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6054 - accuracy: 0.6909\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5718 - accuracy: 0.7259\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5684 - accuracy: 0.7258\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5636 - accuracy: 0.7280\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5603 - accuracy: 0.7297\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5578 - accuracy: 0.7316\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5559 - accuracy: 0.7314\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.7326\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7324\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.7317\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5511 - accuracy: 0.7318\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5506 - accuracy: 0.7318\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5500 - accuracy: 0.7326\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7330\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7333\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7344\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7329\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7336\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7342\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7340\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7333\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7344\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7345\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7346\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7353\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7347\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7355\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7361\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7370\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7361\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7372\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7361\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7369\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7368\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7372\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7370\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7371\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7368\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7368\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7379\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7379\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7375\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7367\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7372\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7379\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5407 - accuracy: 0.7375\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7373\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7379\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7389\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn_2.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_6LQdpkCTSB",
        "outputId": "8c4899a3-5882-47f1-c5be-1a5389886f88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 1s 1ms/step - loss: 0.5547 - accuracy: 0.7256\n",
            "Loss: 0.5547152161598206, Accuracy: 0.7255976796150208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_2.save(\"third_model.h5\")"
      ],
      "metadata": {
        "id": "AbhWKIxfiQDE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third attempt at optimisation"
      ],
      "metadata": {
        "id": "ZWLvT0qTDcWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this attempt I will use the original model used in \"first_attempt.ipynb\" but with\n",
        "# without binning the 'APPLICATION_TYPE' and 'CLASSIFICATION' columns\n",
        "\n",
        "import math\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "# input dimension\n",
        "num_features = X.shape[1]\n",
        "\n",
        "\n",
        "num_neurons_1 = num_features\n",
        "\n",
        "\n",
        "num_neurons_2 = math.floor(num_features/2)\n",
        "\n",
        "\n",
        "num_neurons_3 = math.floor(num_neurons_2)\n",
        "\n",
        "# initalising model\n",
        "\n",
        "nn_3 = tf.keras.models.Sequential()\n",
        "\n",
        "# input layer\n",
        "\n",
        "nn_3.add(tf.keras.layers.Dense(units=num_neurons_1, activation=\"sigmoid\", input_dim=num_features))\n",
        "\n",
        "# First hidden layer\n",
        "nn_3.add(tf.keras.layers.Dense(units=num_neurons_2, activation=\"sigmoid\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn_3.add(tf.keras.layers.Dense(units=num_neurons_3, activation=\"sigmoid\"))\n",
        "\n",
        "# Output layer (single neuron)\n",
        "nn_3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_3.summary()"
      ],
      "metadata": {
        "id": "Nxd6GrmqDfTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e538d5-8cff-445c-a451-d10a6baed8e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 43)                1892      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 21)                924       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 21)                462       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3300 (12.89 KB)\n",
            "Trainable params: 3300 (12.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "fit_model = nn_3.fit(X_train_scaled_2, y_train_2, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFCPL2toa2RL",
        "outputId": "791f5c5b-eb16-4d14-ad3b-33b9c6eb9baa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6080 - accuracy: 0.6883\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.7261\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.7283\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5607 - accuracy: 0.7300\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7306\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5562 - accuracy: 0.7317\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5544 - accuracy: 0.7315\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5536 - accuracy: 0.7317\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5528 - accuracy: 0.7315\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.7332\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5513 - accuracy: 0.7327\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7331\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7326\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7338\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7334\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5487 - accuracy: 0.7331\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7334\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7336\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5475 - accuracy: 0.7338\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7330\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7341\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7348\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7345\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7346\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7350\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7357\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7362\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7356\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7367\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7352\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7368\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7365\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7370\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7371\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7360\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7369\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7374\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7359\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7376\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7380\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7368\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7374\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7377\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7379\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5422 - accuracy: 0.7385\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7381\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7372\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7371\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7386\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn_3.evaluate(X_test_scaled_2,y_test_2,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYYTukMva6tW",
        "outputId": "062b117a-dda3-419a-f105-44030355c956"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 2s 5ms/step - loss: 0.5536 - accuracy: 0.7264\n",
            "Loss: 0.5535574555397034, Accuracy: 0.7264139652252197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_3.save(\"fourth_model.h5\")"
      ],
      "metadata": {
        "id": "dfr6H4wogFiu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_Uchve2hOep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyIO3lFJhSIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}